# <font face="宋体">实验二：王者荣耀英雄数据</font>

​														`JL22110003 邱文韬`

## 实验要求

爬取[王者荣耀英雄数据库](https://db.18183.com/wzry/)至少50个英雄的详细信息，记录于 json 格式的文件中（选做：记录于csv格式的文件中，不计分）

## 实验原理

`requests`库：requests是一个Python HTTP客户端库，它使得发送HTTP请求非常简单。使用requests库，可以方便地发送GET、POST、PUT、DELETE等HTTP请求，并获取响应内容。

`BeautifulSoup`库： BeautifulSoup是一个Python的第三方库，它用于解析HTML和XML文档。BeautifulSoup库可以自动将HTML或XML文档转换成Python对象，使得我们可以使用Python语言来操作文档。

`re`库：re是Python中内置的正则表达式库，它提供了一套用于处理字符串的特殊语法，通过这些语法，我们可以快速地进行字符串的匹配、查找、替换等操作。

`csv`库： csv是Python内置的标准库，它用于读写CSV格式的文件。

`json`库： json是Python内置的标准库，它用于解析和生成JSON（JavaScript Object Notation）格式的数据。

## 实验过程

### 获取英雄详情网址后缀

首先观察网站首页，网址为https://db.18183.com/wzry/

<img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319163612539.png" alt="image-20230319163612539" style="zoom:50%;" />

再进入英雄详情页面，可以看到与首页相比，详情页面多了后缀/hero/16364.html

<img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319163551442.png" alt="image-20230319163551442" style="zoom:50%;" />

多观察几个英雄发现，他们的后缀并不是连续的，也没有一定规律，所以为了能够依次访问到所有英雄的详情页，因此考虑首先爬取每个英雄详情页面对应的网站后缀

<img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318150701113.png" alt="image-20230318150701113" style="zoom:50%;" />

再找到详情页面所在的元素

![image-20230318152619178](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318152619178.png)

发现每个英雄的网址在无序列表`<ul>`中的`<li>`元素里，以`<a href="xxxx">`形式存在。因此，获取网址后缀的思路就是在定位元素位置后，使用正则表达式匹配链接，然后将获取的后缀保存在一个csv文件中。

![image-20230318152702656](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318152702656.png)

#### 代码设计

模块化代码设计：

`getHTMLText`函数：参数为url，即需要请求的网站地址。使用requests库请求网站，获取网站内容。在请求时添加一个头部信息（header），向服务器传递一些请求信息，例如浏览器类型、操作系统、请求来源等。防止被服务器反爬导致请求失败。

```python
def getHTMLText(url):
    head = {
        "User-Agent":
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36 Edg/99.0.1150.46"
    }
    try:
        resp = requests.get(url, timeout=30,headers= head)
        # resp.raise_for_status()
        resp.encoding = 'utf-8'
        return resp.text
    except:
        return ""
```

`fillUnivList`函数：参数为soup，即创建的BeautifulSoup对象。在此函数使用bs4库获取html指定元素内容以及使用re库正则表达式匹配所需要的内容，结果存入links.csv。soup.findAll获取div元素指定class类的内容存入列表。再遍历列表，通过`re.compile('<a href="(.*?)">')`正则表达式匹配指定的链接，因为列表中存在的元素有时会带有空白符\xa0，并且字符串结尾为换行符，所以需要去除空白符并按换行符分隔，然后再对得到的列表逐个进行正则匹配。

```python
def fillUnivList(soup):
    file = open('links.csv', mode='w')
    file.write('link\n')
    Alist  = soup.findAll('div',class_='section hero-result-box mod-bg clearfix')
    linkre = re.compile('<a href="(.*?)">')
    for line in Alist:
        lst = str(line).replace('\xa0', '').split('\n')
        # print(lst)
        for href in lst:
            link = linkre.findall(href)
            if  len(link) > 0:
                print(link)
                file.write(str(link[0]))
                file.write('\n')
```

​	`main`函数：main函数中调用前面已经编写好的函数，最后传入参数url并调用main函数即可运行整个程序。

```python
def main(url):
    html = getHTMLText(url)
    soup = BeautifulSoup(html, "html.parser")
    fillUnivList(soup)
```

```python
url = 'https://db.18183.com/wzry/'
main(url)
得到的结果(部分)如下图
```

![image-20230318162446693](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318162446693.png)

### 爬取英雄信息

来到英雄详情页面，发现初始状态，我们需要爬取的英雄基础属性并没有直接展示出来，因此我一开始认为此页面可能需要模拟鼠标点击事件继而爬取数据。![image-20230318162804869](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318162804869.png)

但是通过检查元素发现基础属性所在的div元素只是style属性设置为不展示，内容还是存在的，所以无需模拟鼠标点击事件，可以直接爬取。并且这里的结构也比较清晰简单，其具有唯一的class属性：otherinfo-datapanel。因此爬取思路为通过定位div元素，再获取无序列表`<ul>`中每一项`<li>`的text，即可得到各项属性内容。

![image-20230318163006369](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318163006369.png)

可以看到英雄名字在元素`<div calss=name-box>`中 ，`<h1>`标签包裹，并且一个详情页面英雄名字是唯一的。因此可以先使用soup.find方法定位此div元素，然后再使用一次find找到该div内的h1标签内容，获取内容的text就得到了英雄名字。

![image-20230318164651196](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318164651196.png)

英雄属性位于元素`<div calss=attr-list>`中，能力和星级存在dl表格中，星星数目在dd的span标签中以class指定，因此只需要获取star-10最后的数字即可，很容易通过正则表达式进行匹配。因此同样可以先使用soup.find方法定位此div元素，在使用findAll将所有dd标签找出来，然后使用正则表达式匹配对应星级即可。

![image-20230318165201331](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318165201331.png)

![image-20230318165354661](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230318165354661.png)

#### 代码设计

同样模块化代码，各函数与上述相同。

`getHTMLText`同样使用requests库请求网页，参数为url，无变化不再赘述。

`fillUnivList`函数：定义两个全局变量Name、Str，其中Name用于记录英雄名字，而Str用于记录当前英雄的所有信息，并用逗号连接便于写入csv文件中。代码如下，首先定位各个指定class的div元素，使用find方法找到h1标签获取英雄名字，使用findAll找到dd标签的内容，然后使用正则表达式匹配span标签中对应的星级。英雄属性在`<li>`标签中，所以在其对应的div元素内，使用findAll找到所有对应的`<li>`标签的text内容，因为存入csv文件只需要冒号以后的内容，所以对获取的text按冒号进行分隔

```python
Name =''
Str = ''
def fillUnivList(soup):
    global Name,Str
    divs  = soup.find('div',class_='otherinfo-datapanel')
    attrs = soup.find('div',class_='attr-list')
    names = soup.find('div',class_='name-box')
    name = names.find('h1')
    Name = name.text
    Str += Name
    ddre =  re.compile('<dd><span class="star star-(.*?)"></span></dd>')
    dds = attrs.findAll('dd')
    for dd in dds:
        Str += ','+ddre.findall(str(dd))[0]
    lis = divs.findAll('li')
    for li in lis:
        Str += ',' +li.text.split("：")[1].strip()
```

`main`函数：main函数与之前的功能类似，即调用getHTMLText、创建BeautifulSoup对象以及fillUnivList调用函数

```python
def main(url):
        html = getHTMLText(url)
        soup = BeautifulSoup(html, "html.parser")
        fillUnivList(soup)
```

`getInfo`函数：在此函数将英雄信息写入csv文件，再读取csv文件的网址后缀作为一个列表，for循环中依次遍历每个英雄的网址后缀，拼接得到目标网址target，为了防止访问频率过高导致IP被封禁，所以调用main函数前使用time.sleep(1)休眠，降低请求频率，main函数结束后，Str即为每个英雄的具体信息，再将Str写入csv文件中。

```python
def getInfo():
    file = open('info.csv', mode='w')
    file.write(
        '序号,英雄名字,生存能力,攻击伤害,技能效果,上手难度,最大生命,最大法力,物理攻击,法术攻击,物理防御,物理减伤率,法术防御,法术减伤率,移速,物理护甲穿透,法术护甲穿透,攻速加成,暴击几率,暴击效果,物理吸血,法术吸血,冷却缩减,攻击范围,韧性,生命回复,法力回复\n')
    linkSuffix = []
    for line in open('links.csv', 'r', encoding='utf-8'):
        linkSuffix.append(line.strip())  # 一次读一行，并且内存不会溢出，去除空行或者空格
    linkSuffix.remove(linkSuffix[0])
    global target, Str
    for index,suffix in enumerate(linkSuffix):
        Str = ''
        target = 'https://db.18183.com/' + suffix
        time.sleep(1)
        main(target)
        file.write(str(index)+','+Str)
        file.write('\n')
        print(str(index)+','+Str)
```

​	由于我选择直接将爬取的信息写入csv文件，而不是以json格式保存，所以为了得到json格式的数据，我编写了一个程序将csv文件转换为json文件。

```python
import csv
import json
with open('info.csv', newline='', encoding='gbk') as csvfile:
    reader = csv.DictReader(csvfile)
    data = [dict(row) for row in reader]
with open('info.json', 'w', encoding='UTF-8') as jsonfile:
    json.dump(data, jsonfile, ensure_ascii=False, indent=4)
```

## DeBug过程

1. 后续读入csv数据时，csv文件的列标题是列表首项，而不是网址后缀，这导致请求网页时发送错误![image-20230319152838202](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319152838202.png)

   所以需要去除首项![image-20230319152954465](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319152954465.png)

2. 读取英雄信息csv文件转换为json文件时，编码报错![image-20230319153151892](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319153151892.png)

   ![image-20230319153212528](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319153212528.png)

   因为文件中有中文，所以要换成国标码gbk，这样就可以正常读取

   ![image-20230319153304451](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319153304451.png)

3. 在使用正则表达式的模式串匹配英雄能力星级时，由于findall函数的对象为字符串，所以这里要使用类型转换，否则会报错，并且这个方法返回的结果是一个列表，而列表存的唯一元素就是对应的星级，所以要取第一个元素即下标为0，一开始没有取首元素，可以正常运行，但是结果不是预期的![image-20230319161511307](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319161511307.png)

4. 在获取网址后缀时，因为使用正则表达式匹配得到的link存在很多空串，导致吸入csv文件的结果有很多空字符，所以在写入前先判断一下link是否为空，只有不为空才写入csv文件![image-20230319162256137](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319162256137.png)

5. 在使用全局变量时，python不同的地方在于全局变量的声明是在函数内，代表这个变量是在函数外就已经定义的全局变量，一开始我在函数外声明global所以报错，查阅资料后改正如下![image-20230319162439217](C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319162439217.png)

## 实验结果

成功爬取了王者荣耀106个英雄的具体信息

`csv`格式数据：有部分英雄的个别属性在原网站就是为空的，所以并不是爬虫程序的问题                                                                                                                           <img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319162821843.png" alt="image-20230319162821843" style="zoom:50%;" />

`json`格式数据：

<img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230319162953034.png" alt="image-20230319162953034" style="zoom:50%;" />

简单的分析一下爬取的数据结果：数据总共有106条记录，即106个英雄的具体信息，每个信息有26列，即每个英雄有26个属性字段

1. 总共有106条数据，其中完整的数据为102条，不完整(即有属性为空)的数据有4条，分别是<img src="C:\Users\社会人\AppData\Roaming\Typora\typora-user-images\image-20230325161039583.png" alt="image-20230325161039583" style="zoom: 50%;" />
原因是在原始网站上，他们的这些属性就是为空的，空属性统计如下：
                                                            ![ex2_柱形图1.0](C:\Users\社会人\Desktop\数据分析与实践\exam2\ex2_柱形图1.0.png)
2. 英雄攻击范围以及生成能力的饼图
                                                                          ![ex2_饼图1.0](C:\Users\社会人\Desktop\数据分析与实践\exam2\ex2_饼图1.0.png)
3. 英雄最大生命/法力的箱线图(已去除异常值)
                                                                                                                                                ![ex2_箱线图1.0](C:\Users\社会人\Desktop\数据分析与实践\exam2\ex2_箱线图1.0.png)









