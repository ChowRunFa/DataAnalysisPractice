# Neural Subgraph Isomorphism Counting

# Basic Information:

- Title: Neural Subgraph Isomorphism Counting (神经子图同构计数)
- Authors: Xin Liu, Haojie Pan, Mutian He, Yangqiu Song, Xin Jiang, Lifeng Shang
- Affiliation: Department of CSE, HKUST (香港科技大学)
- Keywords: Subgraph Isomorphism, Dynamic Memory, Neural Network
- URLs: Paper: https://dl.acm.org/doi/10.1145/3394486.3403247 , GitHub: https://github.com/HKUST-KnowComp/NeuralSubgraphCounting

# 总结

本文提出了一个新的图学习问题：子图同构计数，需要对整个图进行全局推断，这在生物信息学、化学信息学和社交网络分析中被广泛应用。传统的子图同构问题是NP完全的，存在数据集大小限制，这使得训练和基础事实生成具有挑战性。本文提出了一种可扩展的学习框架，使用不同的表示学习架构，针对小型和大型图形。作者提出了一种动态中介注意力记忆网络来计数子图同构，该网络可以推广到更大的图案和数据图，能够加速传统的VF2算法，同时保持可接受的误差。作者在合成和基准数据集上评估了他们的方法，并展示了它在解决子图同构计数问题方面的功效，从而实现了应用于现实世界问题。

# 背景

a. 研究主题和特征： 该文介绍了子图同构计数问题，并提出了神经网络方法来解决它。问题涉及在模式和较大的图形之间找到子图同构数目-保留图形拓扑、顶点标签和边标签，但不保留顶点ID的映射。传统的精确方法Ullmann算法具有高计算复杂度，使其在处理大型图形时不可行。

b. 历史发展： 之前的研究工作中，已有针对子图问题的算法研究。但问题复杂度高，存在数据集规模的限制，因此提出了本论文所述的神经网络方法。

c. 以往的方法： 传统的子图同构计数问题常用精确算法Ullmann算法处理。但算法计算复杂度较高。

d. 以往研究的不足之处： 传统算法复杂度高，不能处理大型数据集。

e. 当前需要解决的问题： 需提出一种新的子图同构计数方法，能够有效地应用于生物信息学、化学信息学和社交网络分析领域。

# 方法

a. 研究的理论基础： 使用不同的表示学习架构来处理小型和大型图形，并使用基于注意力的神经网络体系结构来学习图形和模式的分布式表示，并处理两者之间的成对交互。

b. 论文中提出的技术路线（逐步讲解）： 该文介绍了用于序列和图形的两种编码方法，并讨论了使用CNN、LSTM、Transformers、RGCN和GIN提取高级特征的方法。但由于注意力机制的二次计算成本，本文提出了一种名为动态中介注意记忆网络（DIAMNet）的新神经网络模型，引入了额外的记忆机制，将复杂度降至大约线性，同时保持足够的性能。

c. 任务和方法从学术角度的表现： 本文设计了两个算法：模式生成器和图生成器，用于生成合成数据集，以评估计数子图同构的模型的性能。模式生成器通过生成有向树、分配节点标签、添加随机边和分配边标签来创建模式。图生成器从Dirichlet分布中选择顶点和边的数量，为每个组件生成有向树，分配节点和边标签，添加组件之间的边，并将组件合并为一个大图形。算法使用NEC树来探索匹配的候选区域，并使用随机子程序使数据集难以破解。本文还提供实现细节，如FilterNet用于过滤图形的相关部分和MemAttn模块以解决二次成本问题。最后，本文报告了使用两个算法和用于评估目的的MUTAG数据集生成的合成数据集的详细信息。

# 结论

a. 研究工作的重要意义： 本文提出了一个新的图学习问题：子图同构计数，为生物信息学、化学信息学和社交网络分析等领域提供了有效的解决方案。

b. 创新性、性能和工作量： 本文提出了一种基于动态中介注意力记忆网络的新神经网络模型，提高了计算效率，可以在处理大型图形时带来更好的性能。

c. 研究结论（列出关键点）： 论文使用基于注意力的神经网络架构解决子图同构计数的问题，提出了一种新的神经网络模型DIAMNet，并提供了两个算法用于生成合成数据集来评估模型的性能。在合成和基准数据集上进行了评估，并展示了该方法在解决子图同构计数问题方面的效果。